{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN2+evWZWOJFbJH0VAjVS0R",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Srinidhi231/activity/blob/main/Untitled17.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IY5yakhtt6wk",
        "outputId": "8c4dcae3-359e-40b8-ba46-e38793d37214"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Pastry ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      1.00      0.96      3543\n",
            "           1       0.52      0.04      0.07       301\n",
            "\n",
            "    accuracy                           0.92      3844\n",
            "   macro avg       0.72      0.52      0.52      3844\n",
            "weighted avg       0.89      0.92      0.89      3844\n",
            "\n",
            "--- Z_Scratch ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.99      0.98      3624\n",
            "           1       0.65      0.37      0.47       220\n",
            "\n",
            "    accuracy                           0.95      3844\n",
            "   macro avg       0.81      0.68      0.72      3844\n",
            "weighted avg       0.94      0.95      0.95      3844\n",
            "\n",
            "--- K_Scatch ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98      3162\n",
            "           1       0.91      0.90      0.90       682\n",
            "\n",
            "    accuracy                           0.97      3844\n",
            "   macro avg       0.94      0.94      0.94      3844\n",
            "weighted avg       0.97      0.97      0.97      3844\n",
            "\n",
            "--- Stains ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99      3744\n",
            "           1       0.62      0.66      0.64       100\n",
            "\n",
            "    accuracy                           0.98      3844\n",
            "   macro avg       0.80      0.82      0.81      3844\n",
            "weighted avg       0.98      0.98      0.98      3844\n",
            "\n",
            "--- Dirtiness ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99      3759\n",
            "           1       0.60      0.07      0.13        85\n",
            "\n",
            "    accuracy                           0.98      3844\n",
            "   macro avg       0.79      0.53      0.56      3844\n",
            "weighted avg       0.97      0.98      0.97      3844\n",
            "\n",
            "--- Bumps ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.94      0.86      2918\n",
            "           1       0.57      0.25      0.34       926\n",
            "\n",
            "    accuracy                           0.77      3844\n",
            "   macro avg       0.68      0.59      0.60      3844\n",
            "weighted avg       0.74      0.77      0.74      3844\n",
            "\n",
            "--- Other_Faults ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.89      0.77      2495\n",
            "           1       0.55      0.24      0.34      1349\n",
            "\n",
            "    accuracy                           0.66      3844\n",
            "   macro avg       0.62      0.57      0.56      3844\n",
            "weighted avg       0.64      0.66      0.62      3844\n",
            "\n",
            "Model saved as 'multi_output_rf_model.pkl'\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.multioutput import MultiOutputClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import pickle\n",
        "\n",
        "# Step 1: Load training data\n",
        "train_df = pd.read_csv('train.csv')\n",
        "\n",
        "# Step 2: Split features (X) and target labels (y)\n",
        "X = train_df.drop(columns=['Pastry', 'Z_Scratch', 'K_Scatch', 'Stains', 'Dirtiness', 'Bumps', 'Other_Faults'])\n",
        "y = train_df[['Pastry', 'Z_Scratch', 'K_Scatch', 'Stains', 'Dirtiness', 'Bumps', 'Other_Faults']]\n",
        "\n",
        "# Step 3: Split into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 4: Train a multi-output random forest model\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model = MultiOutputClassifier(rf)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Step 5: Evaluate model on validation data\n",
        "y_pred = model.predict(X_val)\n",
        "for i, col in enumerate(y.columns):\n",
        "    print(f\"--- {col} ---\")\n",
        "    print(classification_report(y_val[col], y_pred[:, i]))\n",
        "\n",
        "# Step 6: Save the trained model to a .pkl file\n",
        "with open('multi_output_rf_model.pkl', 'wb') as file:\n",
        "    pickle.dump(model, file)\n",
        "    print(\"Model saved as 'multi_output_rf_model.pkl'\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import pickle\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.multioutput import MultiOutputClassifier\n",
        "\n",
        "# Step 1: Load the trained model (from the pickle file)\n",
        "with open('multi_output_rf_model.pkl', 'rb') as file:\n",
        "    model = pickle.load(file)\n",
        "\n",
        "# Step 2: Load the test data\n",
        "test_df = pd.read_csv('test.csv')\n",
        "\n",
        "# Step 3: Check the columns in the test dataset\n",
        "print(\"Test data columns:\", test_df.columns)\n",
        "print(\"Test data shape:\", test_df.shape)\n",
        "\n",
        "# Step 4: Load the sample submission to understand the expected format\n",
        "sample_submission = pd.read_csv('sample_submission.csv')\n",
        "print(\"Sample submission shape:\", sample_submission.shape)\n",
        "\n",
        "# Step 5: Define the target label columns\n",
        "label_columns = ['Pastry', 'Z_Scratch', 'K_Scatch', 'Stains', 'Dirtiness', 'Bumps', 'Other_Faults']\n",
        "\n",
        "# Step 6: Prepare the feature data (X_test) by dropping any label columns if present\n",
        "X_test = test_df.drop(columns=[col for col in label_columns if col in test_df.columns])\n",
        "print(\"Feature matrix shape:\", X_test.shape)\n",
        "\n",
        "# Step 7: Make predictions on the test data\n",
        "probabilities = pd.DataFrame(index=X_test.index)\n",
        "\n",
        "# Handle the probability extraction based on the model type\n",
        "if isinstance(model, MultiOutputClassifier):\n",
        "    # For MultiOutputClassifier, extract probabilities for each classifier\n",
        "    estimators = model.estimators_\n",
        "    for i, col in enumerate(label_columns):\n",
        "        # Extract probability for class 1 (positive class)\n",
        "        probabilities[col] = estimators[i].predict_proba(X_test)[:, 1]\n",
        "else:\n",
        "    # If the model is a direct RandomForestClassifier with predict_proba capability\n",
        "    y_pred_prob = model.predict_proba(X_test)\n",
        "    for i, col in enumerate(label_columns):\n",
        "        probabilities[col] = y_pred_prob[i][:, 1]\n",
        "\n",
        "print(\"Probabilities shape:\", probabilities.shape)\n",
        "\n",
        "# Step 8: Ensure we have the same number of predictions as expected in the sample submission\n",
        "# If they don't match, we need to understand why\n",
        "if len(probabilities) != len(sample_submission):\n",
        "    print(f\"WARNING: Number of predictions ({len(probabilities)}) doesn't match sample submission ({len(sample_submission)})\")\n",
        "\n",
        "    # Check if sample_submission has an ID column we can use to align data\n",
        "    id_col = None\n",
        "    for col in sample_submission.columns:\n",
        "        if col not in label_columns:\n",
        "            id_col = col\n",
        "            break\n",
        "\n",
        "    if id_col and id_col in test_df.columns:\n",
        "        print(f\"Using {id_col} to align predictions with sample submission format\")\n",
        "        # Create a new dataframe with sample_submission IDs\n",
        "        aligned_probabilities = pd.DataFrame(index=sample_submission.index)\n",
        "\n",
        "        # Map test predictions to sample submission format using the ID column\n",
        "        for col in label_columns:\n",
        "            # Create a mapping from test ID to probability\n",
        "            prob_map = dict(zip(test_df[id_col], probabilities[col]))\n",
        "            # Map the probabilities to sample submission IDs\n",
        "            aligned_probabilities[col] = sample_submission[id_col].map(prob_map)\n",
        "\n",
        "        probabilities = aligned_probabilities\n",
        "\n",
        "# Step 9: Ensure the order of columns in the submission matches the sample file\n",
        "submission = sample_submission.copy()\n",
        "for col in label_columns:\n",
        "    if col in submission.columns:\n",
        "        submission[col] = probabilities[col].values\n",
        "\n",
        "# Step 10: Verify the submission format\n",
        "print(\"Final submission shape:\", submission.shape)\n",
        "print(\"Submission columns:\", submission.columns)\n",
        "\n",
        "# Step 11: Save the submission file to CSV\n",
        "submission.to_csv('submission.csv', index=False)\n",
        "print(\"Submission file 'submission.csv' created successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tr4RhR0IuJSJ",
        "outputId": "7109ed61-15e3-468c-9d10-23a6ba704634"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test data columns: Index(['id', 'X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum',\n",
            "       'Pixels_Areas', 'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n",
            "       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n",
            "       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n",
            "       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n",
            "       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n",
            "       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n",
            "       'SigmoidOfAreas'],\n",
            "      dtype='object')\n",
            "Test data shape: (12814, 28)\n",
            "Sample submission shape: (12814, 8)\n",
            "Feature matrix shape: (12814, 28)\n",
            "Probabilities shape: (12814, 7)\n",
            "Final submission shape: (12814, 8)\n",
            "Submission columns: Index(['id', 'Pastry', 'Z_Scratch', 'K_Scatch', 'Stains', 'Dirtiness', 'Bumps',\n",
            "       'Other_Faults'],\n",
            "      dtype='object')\n",
            "Submission file 'submission.csv' created successfully!\n"
          ]
        }
      ]
    }
  ]
}